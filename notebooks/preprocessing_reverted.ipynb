{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f48a906",
   "metadata": {},
   "source": [
    "## Preprocessing of Data and Augmentation\n",
    "- smote_\"name of file\" e.g. smote_C4M1 (type = numpy array) for normalized data augmentation with SMOTE (Synthetic Minority Oversampling Technique)\n",
    "- gauss_data_\"name of file\" e.g gauss_data_C3M2 (type = numpy array) for normaliezed data augmentation with gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e54e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d973005",
   "metadata": {},
   "source": [
    "## Read in Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "121becf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/Exercises_SS22/sleeplab_dataset_10hz/patient_29_male_7_years',\n",
       " '../data/Exercises_SS22/sleeplab_dataset_10hz/patient_75_female_5_years',\n",
       " '../data/Exercises_SS22/sleeplab_dataset_10hz/patient_80_female_5_years',\n",
       " '../data/Exercises_SS22/sleeplab_dataset_10hz/patient_89_female_6_years',\n",
       " '../data/Exercises_SS22/sleeplab_dataset_10hz/patient_91_female_7_years']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirname = \"../data/Exercises_SS22/sleeplab_dataset_10hz\"\n",
    "folders = []\n",
    "\n",
    "for folder in os.listdir(dirname):\n",
    "    f = os.path.join(dirname, folder)\n",
    "    x = f.replace('\\\\', '/')\n",
    "    folders.append(x)\n",
    "\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5bf82ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "readings = []\n",
    "names = []\n",
    "\n",
    "for filename in os.listdir(folders[0]):\n",
    "    f = os.path.join(folders[0], filename)\n",
    "    x = f.replace('\\\\', '/')\n",
    "    readings.append(x)\n",
    "    f = filename.replace('.csv','')\n",
    "    names.append(f)\n",
    "    \n",
    "measurements = [pd.read_csv(i, skiprows=1, names=[names[ix]]) for ix, i in enumerate(readings[:-1])]\n",
    "label = pd.read_csv(readings[-1], usecols=['Schlafstadium'])\n",
    "data = pd.concat(measurements, axis=1)\n",
    "converted_label = label.replace(['WK', 'REM', 'N1', 'N2', 'N3'], [0, 1, 2, 3, 4])\n",
    "normalized_df=(data-data.mean())/data.std()\n",
    "segments = np.array([[i] * 300 for i in range(len(converted_label))]).flatten()[:normalized_df.shape[0]]\n",
    "\n",
    "tuples = list(zip(segments, normalized_df.index))\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=[\"Samples\", \"Datapoints\"])\n",
    "multi_index_df = normalized_df.set_index(index)\n",
    "counted = multi_index_df.groupby(level=0).count()\n",
    "smallSampleIndices = counted.loc[counted.BeinLi_10HZ < 300].index\n",
    "if len(smallSampleIndices) > 0:\n",
    "    multi_index_df = multi_index_df.drop(smallSampleIndices)\n",
    "    converted_label = converted_label.drop(smallSampleIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c3e0260",
   "metadata": {},
   "outputs": [],
   "source": [
    "readings_2 = []\n",
    "names_2 = []\n",
    "\n",
    "\n",
    "for filename in os.listdir(folders[1]):\n",
    "    f = os.path.join(folders[1], filename)\n",
    "    x = f.replace('\\\\', '/')\n",
    "    readings_2.append(x)\n",
    "    f = filename.replace('.csv','')\n",
    "    names_2.append(f)\n",
    "    # create single df\n",
    "    \n",
    "#read data\n",
    "measurements_2 = [pd.read_csv(i, skiprows=1, names=[names_2[ix]]) for ix, i in enumerate(readings_2[:-1])]\n",
    "label_2 = pd.read_csv(readings_2[-1], usecols=['Schlafstadium'])\n",
    "label_2.index += 1091\n",
    "# concat all single files\n",
    "data_2 = pd.concat(measurements_2, axis=1)\n",
    "# convert labels to ints\n",
    "converted_label_2 = label_2.replace(['WK', 'REM', 'N1', 'N2', 'N3'], [0, 1, 2, 3, 4])\n",
    "# normalize the data, because some paper said to do so\n",
    "normalized_df_2 = (data_2-data_2.mean())/data_2.std()\n",
    "segments_2 = np.array([[i] * 300 for i in range(len(converted_label_2))]).flatten()[:normalized_df_2.shape[0]]\n",
    "segments_2 += 1091\n",
    "normalized_df_2.index += 1091\n",
    "# create multi index dataframe\n",
    "tuples_2 = list(zip(segments_2, normalized_df_2.index))\n",
    "\n",
    "index_2 = pd.MultiIndex.from_tuples(tuples_2, names=[\"Samples\", \"Datapoints\"])\n",
    "multi_index_df_2 = normalized_df_2.set_index(index_2)\n",
    "# drop the sample, that isn't big enough\n",
    "counted_2 = multi_index_df_2.groupby(level=0).count()\n",
    "smallSampleIndices_2 = counted_2.loc[counted_2.BeinLi_10HZ < 300].index\n",
    "if len(smallSampleIndices_2) > 0:\n",
    "    multi_index_df_2 = multi_index_df_2.drop(smallSampleIndices_2)\n",
    "    converted_label_2 = converted_label_2.drop(smallSampleIndices_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d0433c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>BeinLi_10HZ</th>\n",
       "      <th>BeinRe_10HZ</th>\n",
       "      <th>C3M2_10HZ</th>\n",
       "      <th>C4M1_10HZ</th>\n",
       "      <th>EMG_10HZ</th>\n",
       "      <th>F3M2_10HZ</th>\n",
       "      <th>F4M1_10HZ</th>\n",
       "      <th>LEOGM2_10HZ</th>\n",
       "      <th>O1M2_10HZ</th>\n",
       "      <th>O2M1_10HZ</th>\n",
       "      <th>REOGM1_10HZ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samples</th>\n",
       "      <th>Datapoints</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1091</th>\n",
       "      <th>1091</th>\n",
       "      <td>0.009903</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.091553</td>\n",
       "      <td>-0.038920</td>\n",
       "      <td>0.017304</td>\n",
       "      <td>-0.067191</td>\n",
       "      <td>0.074941</td>\n",
       "      <td>0.104402</td>\n",
       "      <td>-0.320144</td>\n",
       "      <td>0.137338</td>\n",
       "      <td>0.526640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>0.009903</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.091553</td>\n",
       "      <td>-0.038920</td>\n",
       "      <td>0.017304</td>\n",
       "      <td>-0.067191</td>\n",
       "      <td>0.074941</td>\n",
       "      <td>0.104402</td>\n",
       "      <td>-0.320144</td>\n",
       "      <td>0.137338</td>\n",
       "      <td>0.526640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>0.009903</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.091553</td>\n",
       "      <td>-0.038920</td>\n",
       "      <td>0.017304</td>\n",
       "      <td>-0.067191</td>\n",
       "      <td>0.074941</td>\n",
       "      <td>0.104402</td>\n",
       "      <td>-0.320144</td>\n",
       "      <td>0.137338</td>\n",
       "      <td>0.526640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>0.009903</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.091553</td>\n",
       "      <td>-0.038920</td>\n",
       "      <td>0.017304</td>\n",
       "      <td>-0.067191</td>\n",
       "      <td>0.074941</td>\n",
       "      <td>0.104402</td>\n",
       "      <td>-0.320144</td>\n",
       "      <td>0.137338</td>\n",
       "      <td>0.526640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>0.009903</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.091553</td>\n",
       "      <td>-0.038920</td>\n",
       "      <td>0.017304</td>\n",
       "      <td>-0.067191</td>\n",
       "      <td>0.074941</td>\n",
       "      <td>0.104402</td>\n",
       "      <td>-0.320144</td>\n",
       "      <td>0.137338</td>\n",
       "      <td>0.526640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2311</th>\n",
       "      <th>367386</th>\n",
       "      <td>0.335723</td>\n",
       "      <td>-1.267304</td>\n",
       "      <td>-0.064566</td>\n",
       "      <td>0.185251</td>\n",
       "      <td>2.523777</td>\n",
       "      <td>0.040725</td>\n",
       "      <td>0.281393</td>\n",
       "      <td>0.362348</td>\n",
       "      <td>0.519440</td>\n",
       "      <td>0.055299</td>\n",
       "      <td>-0.367360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367387</th>\n",
       "      <td>-0.424523</td>\n",
       "      <td>-0.088911</td>\n",
       "      <td>-0.162140</td>\n",
       "      <td>0.092491</td>\n",
       "      <td>0.184402</td>\n",
       "      <td>-0.252190</td>\n",
       "      <td>-0.585706</td>\n",
       "      <td>-0.042996</td>\n",
       "      <td>0.500783</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>-0.866948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367388</th>\n",
       "      <td>0.552936</td>\n",
       "      <td>-0.179556</td>\n",
       "      <td>-0.045051</td>\n",
       "      <td>-0.031190</td>\n",
       "      <td>-0.149794</td>\n",
       "      <td>-0.159690</td>\n",
       "      <td>-0.441189</td>\n",
       "      <td>0.030703</td>\n",
       "      <td>0.407496</td>\n",
       "      <td>0.246723</td>\n",
       "      <td>-0.577713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367389</th>\n",
       "      <td>0.227116</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>-0.493892</td>\n",
       "      <td>-0.123951</td>\n",
       "      <td>-1.319482</td>\n",
       "      <td>-0.329273</td>\n",
       "      <td>-0.812803</td>\n",
       "      <td>-0.208818</td>\n",
       "      <td>0.202264</td>\n",
       "      <td>-0.327549</td>\n",
       "      <td>-0.682889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367390</th>\n",
       "      <td>0.118510</td>\n",
       "      <td>-0.179556</td>\n",
       "      <td>-0.337773</td>\n",
       "      <td>0.053841</td>\n",
       "      <td>-0.316893</td>\n",
       "      <td>-0.128857</td>\n",
       "      <td>0.095586</td>\n",
       "      <td>-0.190394</td>\n",
       "      <td>-0.282829</td>\n",
       "      <td>0.274069</td>\n",
       "      <td>0.263699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366300 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    BeinLi_10HZ  BeinRe_10HZ  C3M2_10HZ  C4M1_10HZ  EMG_10HZ  \\\n",
       "Samples Datapoints                                                             \n",
       "1091    1091           0.009903     0.001735   0.091553  -0.038920  0.017304   \n",
       "        1092           0.009903     0.001735   0.091553  -0.038920  0.017304   \n",
       "        1093           0.009903     0.001735   0.091553  -0.038920  0.017304   \n",
       "        1094           0.009903     0.001735   0.091553  -0.038920  0.017304   \n",
       "        1095           0.009903     0.001735   0.091553  -0.038920  0.017304   \n",
       "...                         ...          ...        ...        ...       ...   \n",
       "2311    367386         0.335723    -1.267304  -0.064566   0.185251  2.523777   \n",
       "        367387        -0.424523    -0.088911  -0.162140   0.092491  0.184402   \n",
       "        367388         0.552936    -0.179556  -0.045051  -0.031190 -0.149794   \n",
       "        367389         0.227116     0.001735  -0.493892  -0.123951 -1.319482   \n",
       "        367390         0.118510    -0.179556  -0.337773   0.053841 -0.316893   \n",
       "\n",
       "                    F3M2_10HZ  F4M1_10HZ  LEOGM2_10HZ  O1M2_10HZ  O2M1_10HZ  \\\n",
       "Samples Datapoints                                                            \n",
       "1091    1091        -0.067191   0.074941     0.104402  -0.320144   0.137338   \n",
       "        1092        -0.067191   0.074941     0.104402  -0.320144   0.137338   \n",
       "        1093        -0.067191   0.074941     0.104402  -0.320144   0.137338   \n",
       "        1094        -0.067191   0.074941     0.104402  -0.320144   0.137338   \n",
       "        1095        -0.067191   0.074941     0.104402  -0.320144   0.137338   \n",
       "...                       ...        ...          ...        ...        ...   \n",
       "2311    367386       0.040725   0.281393     0.362348   0.519440   0.055299   \n",
       "        367387      -0.252190  -0.585706    -0.042996   0.500783   0.000607   \n",
       "        367388      -0.159690  -0.441189     0.030703   0.407496   0.246723   \n",
       "        367389      -0.329273  -0.812803    -0.208818   0.202264  -0.327549   \n",
       "        367390      -0.128857   0.095586    -0.190394  -0.282829   0.274069   \n",
       "\n",
       "                    REOGM1_10HZ  \n",
       "Samples Datapoints               \n",
       "1091    1091           0.526640  \n",
       "        1092           0.526640  \n",
       "        1093           0.526640  \n",
       "        1094           0.526640  \n",
       "        1095           0.526640  \n",
       "...                         ...  \n",
       "2311    367386        -0.367360  \n",
       "        367387        -0.866948  \n",
       "        367388        -0.577713  \n",
       "        367389        -0.682889  \n",
       "        367390         0.263699  \n",
       "\n",
       "[366300 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "192f66ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_frame = pd.concat([multi_index_df, multi_index_df_2])\n",
    "double_label = pd.concat([converted_label, converted_label_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45b8fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e07d1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ix, test_ix = train_test_split(double_frame.index.levels[0][:-1], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fd7466f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_X = double_frame.loc[train_ix]\n",
    "train_y = double_label.loc[train_ix]\n",
    "test_X = double_frame.loc[test_ix]\n",
    "test_y = double_label.loc[test_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1305562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.reset_index(0)[train_X.reset_index(0).Samples==92].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed38b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, label_df):\n",
    "        self.dataframe = dataframe\n",
    "        self.label_df = label_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        output = torch.tensor(self.dataframe.loc[list(set(self.dataframe.reset_index(0).Samples))[idx]].values.astype(np.float32)).unsqueeze(0)\n",
    "        label = self.label_df.loc[list(set(self.dataframe.reset_index(0).Samples))[idx]].values[0]\n",
    "        return output, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a120441",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_X, train_y)\n",
    "test_dataset = CustomDataset(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03dab204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f255653",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepClassification(ClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Conv2d(1, 20, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(20),\n",
    "            nn.Conv2d(20, 40, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        \n",
    "            nn.Conv2d(40, 80, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(80),\n",
    "            nn.Conv2d(80 ,80, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(80, 120, kernel_size = 2, stride = 1, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(120),\n",
    "            nn.Conv2d(120,120, kernel_size = 2, stride = 1, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(120, 160, kernel_size = 2, stride = 1, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.Conv2d(160,160, kernel_size = 2, stride = 1, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(160, 240, kernel_size = 2, stride = 1, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(240),\n",
    "            nn.Conv2d(240,240, kernel_size = 2, stride = 1, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "979f12d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "  \n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59881f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 8.2700, val_loss: 8.1243, val_acc: 0.2582\n",
      "Epoch [1], train_loss: 8.1020, val_loss: 8.0893, val_acc: 0.2303\n",
      "Epoch [2], train_loss: 8.0813, val_loss: 8.0765, val_acc: 0.2237\n",
      "Epoch [3], train_loss: 8.0747, val_loss: 8.0740, val_acc: 0.2188\n",
      "Epoch [4], train_loss: 8.0736, val_loss: 8.0737, val_acc: 0.2089\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m opt_func \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mRAdam\n\u001b[0;32m     10\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\u001b[38;5;66;03m#fitting the model on training data and record the result after each epoch\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     20\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     22\u001b[0m     loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     23\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    560\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    563\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 13\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSamples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     14\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe\u001b[38;5;241m.\u001b[39mreset_index(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mSamples))[idx]]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, label\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1202\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;66;03m# GH#5667 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3857\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3854\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m   3856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, MultiIndex):\n\u001b[1;32m-> 3857\u001b[0m     loc, new_index \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_loc_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3858\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m drop_level:\n\u001b[0;32m   3859\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_integer(loc):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:3113\u001b[0m, in \u001b[0;36mMultiIndex._get_loc_level\u001b[1;34m(self, key, level)\u001b[0m\n\u001b[0;32m   3111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m indexer, maybe_mi_droplevels(indexer, ilevels)\n\u001b[0;32m   3112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3113\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_level_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3115\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m   3116\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels[level]\u001b[38;5;241m.\u001b[39m_supports_partial_string_indexing\n\u001b[0;32m   3117\u001b[0m     ):\n\u001b[0;32m   3118\u001b[0m         \u001b[38;5;66;03m# check to see if we did an exact lookup vs sliced\u001b[39;00m\n\u001b[0;32m   3119\u001b[0m         check \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels[level]\u001b[38;5;241m.\u001b[39mget_loc(key)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:3231\u001b[0m, in \u001b[0;36mMultiIndex._get_level_indexer\u001b[1;34m(self, key, level, indexer)\u001b[0m\n\u001b[0;32m   3228\u001b[0m     locs \u001b[38;5;241m=\u001b[39m (level_codes \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mstart) \u001b[38;5;241m&\u001b[39m (level_codes \u001b[38;5;241m<\u001b[39m idx\u001b[38;5;241m.\u001b[39mstop)\n\u001b[0;32m   3229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m locs\n\u001b[1;32m-> 3231\u001b[0m locs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mlevel_codes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m locs\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   3234\u001b[0m     \u001b[38;5;66;03m# The label is present in self.levels[level] but unused:\u001b[39;00m\n\u001b[0;32m   3235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = SleepClassification()\n",
    "\n",
    "num_epochs = 10\n",
    "opt_func = torch.optim.RAdam\n",
    "lr = 0.001#fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_dataloader, test_dataloader, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea37d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa009d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
