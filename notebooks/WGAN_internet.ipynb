{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3c3c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a wgan for generating handwritten digits\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras import backend\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.constraints import Constraint\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc38c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip model weights to a given hypercube\n",
    "class ClipConstraint(Constraint):\n",
    "\t# set clip value when initialized\n",
    "\tdef __init__(self, clip_value):\n",
    "\t\tself.clip_value = clip_value\n",
    "\n",
    "\t# clip model weights to hypercube\n",
    "\tdef __call__(self, weights):\n",
    "\t\treturn backend.clip(weights, -self.clip_value, self.clip_value)\n",
    "\n",
    "\t# get the config\n",
    "\tdef get_config(self):\n",
    "\t\treturn {'clip_value': self.clip_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ad3bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate wasserstein loss\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "\treturn backend.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf57e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone critic model\n",
    "def define_critic(in_shape=(28,28,1)):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# weight constraint\n",
    "\tconst = ClipConstraint(0.01)\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\t# downsample to 14x14\n",
    "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# downsample to 7x7\n",
    "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# scoring, linear activation\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1))\n",
    "\t# compile model\n",
    "\topt = RMSprop(lr=0.00005)\n",
    "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7076a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(latent_dim):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\t# foundation for 7x7 image\n",
    "\tn_nodes = 128 * 7 * 7\n",
    "\tmodel.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(Reshape((7, 7, 128)))\n",
    "\t# upsample to 14x14\n",
    "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# upsample to 28x28\n",
    "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# output 28x28x1\n",
    "\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc9cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and critic model, for updating the generator\n",
    "def define_gan(generator, critic):\n",
    "\t# make weights in the critic not trainable\n",
    "\tfor layer in critic.layers:\n",
    "\t\tif not isinstance(layer, BatchNormalization):\n",
    "\t\t\tlayer.trainable = False\n",
    "\t# connect them\n",
    "\tmodel = Sequential()\n",
    "\t# add generator\n",
    "\tmodel.add(generator)\n",
    "\t# add the critic\n",
    "\tmodel.add(critic)\n",
    "\t# compile model\n",
    "\topt = RMSprop(lr=0.00005)\n",
    "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1039f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "def load_real_samples():\n",
    "\t# load dataset\n",
    "\t(trainX, trainy), (_, _) = load_data()\n",
    "\t# select all of the examples for a given class\n",
    "\tselected_ix = trainy == 7\n",
    "\tX = trainX[selected_ix]\n",
    "\t# expand to 3d, e.g. add channels\n",
    "\tX = expand_dims(X, axis=-1)\n",
    "\t# convert from ints to floats\n",
    "\tX = X.astype('float32')\n",
    "\t# scale from [0,255] to [-1,1]\n",
    "\tX = (X - 127.5) / 127.5\n",
    "\treturn X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1137eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\t# choose random instances\n",
    "\tix = randint(0, dataset.shape[0], n_samples)\n",
    "\t# select images\n",
    "\tX = dataset[ix]\n",
    "\t# generate class labels, -1 for 'real'\n",
    "\ty = -ones((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba03176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
    "\treturn x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5866ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "\t# generate points in latent space\n",
    "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels with 1.0 for 'fake'\n",
    "\ty = ones((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fa9e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
    "\t# prepare fake examples\n",
    "\tX, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "\t# scale from [-1,1] to [0,1]\n",
    "\tX = (X + 1) / 2.0\n",
    "\t# plot images\n",
    "\tfor i in range(10 * 10):\n",
    "\t\t# define subplot\n",
    "\t\tpyplot.subplot(10, 10, 1 + i)\n",
    "\t\t# turn off axis\n",
    "\t\tpyplot.axis('off')\n",
    "\t\t# plot raw pixel data\n",
    "\t\tpyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "\t# save plot to file\n",
    "\tfilename1 = 'generated_plot_%04d.png' % (step+1)\n",
    "\tpyplot.savefig(filename1)\n",
    "\tpyplot.close()\n",
    "\t# save the generator model\n",
    "\tfilename2 = 'model_%04d.h5' % (step+1)\n",
    "\tg_model.save(filename2)\n",
    "\tprint('>Saved: %s and %s' % (filename1, filename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09628cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a line plot of loss for the gan and save to file\n",
    "def plot_history(d1_hist, d2_hist, g_hist):\n",
    "\t# plot history\n",
    "\tpyplot.plot(d1_hist, label='crit_real')\n",
    "\tpyplot.plot(d2_hist, label='crit_fake')\n",
    "\tpyplot.plot(g_hist, label='gen')\n",
    "\tpyplot.legend()\n",
    "\tpyplot.savefig('plot_line_plot_loss.png')\n",
    "\tpyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "905a6a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and critic\n",
    "def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=64, n_critic=5):\n",
    "\t# calculate the number of batches per training epoch\n",
    "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "\t# calculate the number of training iterations\n",
    "\tn_steps = bat_per_epo * n_epochs\n",
    "\t# calculate the size of half a batch of samples\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# lists for keeping track of loss\n",
    "\tc1_hist, c2_hist, g_hist = list(), list(), list()\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_steps):\n",
    "\t\t# update the critic more than the generator\n",
    "\t\tc1_tmp, c2_tmp = list(), list()\n",
    "\t\tfor _ in range(n_critic):\n",
    "\t\t\t# get randomly selected 'real' samples\n",
    "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "\t\t\t# update critic model weights\n",
    "\t\t\tc_loss1 = c_model.train_on_batch(X_real, y_real)\n",
    "\t\t\tc1_tmp.append(c_loss1)\n",
    "\t\t\t# generate 'fake' examples\n",
    "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "\t\t\t# update critic model weights\n",
    "\t\t\tc_loss2 = c_model.train_on_batch(X_fake, y_fake)\n",
    "\t\t\tc2_tmp.append(c_loss2)\n",
    "\t\t# store critic loss\n",
    "\t\tc1_hist.append(mean(c1_tmp))\n",
    "\t\tc2_hist.append(mean(c2_tmp))\n",
    "\t\t# prepare points in latent space as input for the generator\n",
    "\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
    "\t\t# create inverted labels for the fake samples\n",
    "\t\ty_gan = -ones((n_batch, 1))\n",
    "\t\t# update the generator via the critic's error\n",
    "\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "\t\tg_hist.append(g_loss)\n",
    "\t\t# summarize loss on this batch\n",
    "\t\tprint('>%d, c1=%.3f, c2=%.3f g=%.3f' % (i+1, c1_hist[-1], c2_hist[-1], g_loss))\n",
    "\t\t# evaluate the model performance every 'epoch'\n",
    "\t\tif (i+1) % bat_per_epo == 0:\n",
    "\t\t\tsummarize_performance(i, g_model, latent_dim)\n",
    "\t# line plots of loss\n",
    "\tplot_history(c1_hist, c2_hist, g_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e24ff14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 14:43:46.556050: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-02 14:43:46.556156: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuel/miniforge3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11493376/11490434 [==============================] - 4s 0us/step\n",
      "11501568/11490434 [==============================] - 4s 0us/step\n",
      "(6265, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 14:43:51.721766: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-02 14:43:51.721851: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-02 14:43:54.592868: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-02 14:43:55.473317: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, c1=-2.313, c2=-0.012 g=-0.115\n",
      ">2, c1=-6.766, c2=0.084 g=-1.282\n",
      ">3, c1=-10.388, c2=0.162 g=-2.388\n",
      ">4, c1=-12.464, c2=0.247 g=-3.712\n",
      ">5, c1=-14.493, c2=0.329 g=-4.716\n",
      ">6, c1=-16.151, c2=0.427 g=-6.021\n",
      ">7, c1=-17.567, c2=0.496 g=-6.608\n",
      ">8, c1=-19.308, c2=0.573 g=-7.796\n",
      ">9, c1=-20.076, c2=0.632 g=-8.611\n",
      ">10, c1=-21.303, c2=0.728 g=-9.135\n",
      ">11, c1=-22.379, c2=0.794 g=-10.541\n",
      ">12, c1=-23.204, c2=0.888 g=-11.308\n",
      ">13, c1=-24.307, c2=0.946 g=-12.001\n",
      ">14, c1=-24.503, c2=1.069 g=-12.869\n",
      ">15, c1=-25.784, c2=1.142 g=-13.686\n",
      ">16, c1=-26.706, c2=1.248 g=-14.145\n",
      ">17, c1=-27.214, c2=1.315 g=-15.164\n",
      ">18, c1=-27.642, c2=1.397 g=-15.841\n",
      ">19, c1=-28.537, c2=1.495 g=-16.655\n",
      ">20, c1=-29.109, c2=1.533 g=-17.496\n",
      ">21, c1=-29.803, c2=1.607 g=-17.827\n",
      ">22, c1=-30.047, c2=1.611 g=-18.397\n",
      ">23, c1=-30.842, c2=1.516 g=-19.498\n",
      ">24, c1=-31.071, c2=1.500 g=-19.315\n",
      ">25, c1=-31.872, c2=1.366 g=-19.909\n",
      ">26, c1=-32.580, c2=1.172 g=-20.693\n",
      ">27, c1=-32.220, c2=0.810 g=-21.057\n",
      ">28, c1=-32.577, c2=0.489 g=-22.179\n",
      ">29, c1=-34.459, c2=-0.166 g=-21.990\n",
      ">30, c1=-34.704, c2=-0.694 g=-22.886\n",
      ">31, c1=-34.684, c2=-1.472 g=-23.357\n",
      ">32, c1=-34.828, c2=-2.440 g=-23.922\n",
      ">33, c1=-35.609, c2=-3.328 g=-24.380\n",
      ">34, c1=-35.712, c2=-4.540 g=-24.736\n",
      ">35, c1=-36.792, c2=-5.655 g=-26.167\n",
      ">36, c1=-37.078, c2=-6.798 g=-26.439\n",
      ">37, c1=-37.791, c2=-8.336 g=-27.248\n",
      ">38, c1=-38.585, c2=-9.521 g=-27.648\n",
      ">39, c1=-37.515, c2=-11.055 g=-28.754\n",
      ">40, c1=-38.733, c2=-12.734 g=-29.968\n",
      ">41, c1=-39.238, c2=-14.028 g=-30.876\n",
      ">42, c1=-39.804, c2=-15.770 g=-31.129\n",
      ">43, c1=-40.358, c2=-16.922 g=-31.497\n",
      ">44, c1=-41.100, c2=-18.669 g=-32.421\n",
      ">45, c1=-41.458, c2=-19.901 g=-33.768\n",
      ">46, c1=-42.536, c2=-21.578 g=-34.818\n",
      ">47, c1=-42.617, c2=-22.621 g=-35.251\n",
      ">48, c1=-43.321, c2=-24.114 g=-35.731\n",
      ">49, c1=-43.435, c2=-25.176 g=-36.890\n",
      ">50, c1=-44.788, c2=-26.497 g=-38.100\n",
      ">51, c1=-45.263, c2=-27.420 g=-37.911\n",
      ">52, c1=-45.843, c2=-28.830 g=-38.864\n",
      ">53, c1=-46.408, c2=-29.658 g=-39.876\n",
      ">54, c1=-47.289, c2=-30.857 g=-40.821\n",
      ">55, c1=-47.279, c2=-31.945 g=-42.693\n",
      ">56, c1=-48.558, c2=-32.874 g=-43.177\n",
      ">57, c1=-49.439, c2=-33.700 g=-43.501\n",
      ">58, c1=-50.032, c2=-34.999 g=-43.844\n",
      ">59, c1=-49.823, c2=-35.580 g=-44.907\n",
      ">60, c1=-51.056, c2=-36.604 g=-45.661\n",
      ">61, c1=-50.980, c2=-37.555 g=-46.876\n",
      ">62, c1=-52.659, c2=-38.354 g=-47.413\n",
      ">63, c1=-52.731, c2=-39.133 g=-48.360\n",
      ">64, c1=-53.486, c2=-40.221 g=-49.019\n",
      ">65, c1=-53.766, c2=-40.764 g=-50.423\n",
      ">66, c1=-54.800, c2=-41.819 g=-50.969\n",
      ">67, c1=-55.065, c2=-42.522 g=-51.476\n",
      ">68, c1=-56.464, c2=-43.569 g=-52.080\n",
      ">69, c1=-56.723, c2=-43.980 g=-52.928\n",
      ">70, c1=-57.051, c2=-45.191 g=-53.733\n",
      ">71, c1=-57.205, c2=-45.756 g=-54.610\n",
      ">72, c1=-58.939, c2=-46.735 g=-56.051\n",
      ">73, c1=-59.821, c2=-47.304 g=-56.373\n",
      ">74, c1=-59.442, c2=-48.311 g=-57.303\n",
      ">75, c1=-60.736, c2=-48.980 g=-57.540\n",
      ">76, c1=-61.152, c2=-49.799 g=-58.921\n",
      ">77, c1=-61.893, c2=-50.511 g=-59.355\n",
      ">78, c1=-62.326, c2=-51.276 g=-59.817\n",
      ">79, c1=-64.021, c2=-52.056 g=-60.846\n",
      ">80, c1=-64.388, c2=-52.804 g=-62.434\n",
      ">81, c1=-64.999, c2=-53.533 g=-62.443\n",
      ">82, c1=-66.239, c2=-54.489 g=-63.651\n",
      ">83, c1=-65.625, c2=-55.123 g=-64.540\n",
      ">84, c1=-66.877, c2=-56.064 g=-65.209\n",
      ">85, c1=-67.295, c2=-56.623 g=-66.045\n",
      ">86, c1=-67.958, c2=-57.534 g=-67.095\n",
      ">87, c1=-69.012, c2=-58.009 g=-67.970\n",
      ">88, c1=-69.937, c2=-58.970 g=-68.933\n",
      ">89, c1=-70.323, c2=-59.485 g=-68.412\n",
      ">90, c1=-70.485, c2=-60.537 g=-69.478\n",
      ">91, c1=-71.589, c2=-61.143 g=-70.985\n",
      ">92, c1=-72.170, c2=-62.008 g=-71.568\n",
      ">93, c1=-73.282, c2=-62.720 g=-72.342\n",
      ">94, c1=-73.751, c2=-63.465 g=-72.990\n",
      ">95, c1=-74.230, c2=-64.201 g=-73.954\n",
      ">96, c1=-74.193, c2=-64.956 g=-74.459\n",
      ">97, c1=-75.286, c2=-65.793 g=-76.088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 14:44:25.975953: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: generated_plot_0097.png and model_0097.h5\n",
      ">98, c1=-76.799, c2=-66.400 g=-76.009\n",
      ">99, c1=-76.353, c2=-67.378 g=-77.460\n",
      ">100, c1=-77.721, c2=-67.865 g=-77.253\n",
      ">101, c1=-78.902, c2=-68.859 g=-78.663\n",
      ">102, c1=-80.042, c2=-69.219 g=-79.815\n",
      ">103, c1=-79.900, c2=-70.358 g=-80.644\n",
      ">104, c1=-79.870, c2=-70.966 g=-81.412\n",
      ">105, c1=-81.925, c2=-71.887 g=-82.843\n",
      ">106, c1=-82.710, c2=-72.341 g=-82.958\n",
      ">107, c1=-83.864, c2=-73.369 g=-84.257\n",
      ">108, c1=-83.751, c2=-73.979 g=-85.210\n",
      ">109, c1=-84.831, c2=-74.619 g=-85.679\n",
      ">110, c1=-85.555, c2=-75.645 g=-86.798\n",
      ">111, c1=-85.897, c2=-76.302 g=-87.836\n",
      ">112, c1=-86.939, c2=-76.870 g=-88.338\n",
      ">113, c1=-87.253, c2=-77.851 g=-89.435\n",
      ">114, c1=-88.156, c2=-78.397 g=-88.951\n",
      ">115, c1=-89.073, c2=-79.439 g=-91.146\n",
      ">116, c1=-89.499, c2=-79.981 g=-91.989\n",
      ">117, c1=-90.307, c2=-80.851 g=-92.770\n",
      ">118, c1=-90.846, c2=-81.628 g=-92.649\n",
      ">119, c1=-92.046, c2=-82.338 g=-94.306\n",
      ">120, c1=-92.278, c2=-83.069 g=-95.128\n",
      ">121, c1=-93.353, c2=-83.806 g=-96.317\n",
      ">122, c1=-94.007, c2=-84.540 g=-97.205\n",
      ">123, c1=-94.910, c2=-85.264 g=-97.559\n",
      ">124, c1=-94.807, c2=-86.202 g=-99.137\n",
      ">125, c1=-96.411, c2=-86.733 g=-99.103\n",
      ">126, c1=-97.028, c2=-87.766 g=-100.483\n",
      ">127, c1=-97.566, c2=-88.352 g=-101.636\n",
      ">128, c1=-98.679, c2=-89.150 g=-102.300\n",
      ">129, c1=-98.524, c2=-89.800 g=-102.714\n",
      ">130, c1=-99.880, c2=-90.620 g=-104.384\n",
      ">131, c1=-100.294, c2=-91.530 g=-104.968\n",
      ">132, c1=-101.647, c2=-92.216 g=-105.942\n",
      ">133, c1=-102.048, c2=-92.928 g=-106.830\n",
      ">134, c1=-102.041, c2=-93.831 g=-107.508\n",
      ">135, c1=-103.001, c2=-94.499 g=-108.499\n",
      ">136, c1=-104.467, c2=-95.300 g=-108.739\n",
      ">137, c1=-105.492, c2=-96.216 g=-110.207\n",
      ">138, c1=-105.865, c2=-96.686 g=-111.142\n",
      ">139, c1=-105.875, c2=-97.578 g=-112.134\n",
      ">140, c1=-107.472, c2=-98.363 g=-112.418\n",
      ">141, c1=-108.783, c2=-99.076 g=-113.453\n",
      ">142, c1=-108.508, c2=-100.080 g=-114.237\n",
      ">143, c1=-109.568, c2=-100.787 g=-115.252\n",
      ">144, c1=-110.484, c2=-101.443 g=-115.884\n",
      ">145, c1=-110.744, c2=-102.322 g=-116.583\n",
      ">146, c1=-111.692, c2=-103.087 g=-117.597\n",
      ">147, c1=-112.987, c2=-103.776 g=-118.832\n",
      ">148, c1=-113.471, c2=-104.531 g=-119.349\n",
      ">149, c1=-114.444, c2=-105.425 g=-120.032\n",
      ">150, c1=-114.535, c2=-106.256 g=-121.331\n",
      ">151, c1=-116.699, c2=-106.848 g=-121.926\n",
      ">152, c1=-116.718, c2=-107.733 g=-122.900\n",
      ">153, c1=-117.970, c2=-108.494 g=-123.319\n",
      ">154, c1=-118.252, c2=-109.275 g=-124.237\n",
      ">155, c1=-118.753, c2=-110.040 g=-125.479\n",
      ">156, c1=-119.782, c2=-110.789 g=-126.387\n",
      ">157, c1=-119.861, c2=-111.639 g=-127.002\n",
      ">158, c1=-121.680, c2=-112.307 g=-127.506\n",
      ">159, c1=-122.688, c2=-113.204 g=-128.728\n",
      ">160, c1=-122.950, c2=-113.835 g=-129.148\n",
      ">161, c1=-123.858, c2=-114.805 g=-130.684\n",
      ">162, c1=-124.701, c2=-115.410 g=-131.831\n",
      ">163, c1=-125.945, c2=-116.270 g=-131.942\n",
      ">164, c1=-126.816, c2=-117.198 g=-133.057\n",
      ">165, c1=-126.879, c2=-117.729 g=-133.354\n",
      ">166, c1=-127.043, c2=-118.750 g=-134.890\n",
      ">167, c1=-128.420, c2=-119.528 g=-135.858\n",
      ">168, c1=-129.362, c2=-120.291 g=-136.908\n",
      ">169, c1=-130.033, c2=-120.895 g=-137.510\n",
      ">170, c1=-130.937, c2=-121.865 g=-137.813\n",
      ">171, c1=-131.024, c2=-122.723 g=-139.305\n",
      ">172, c1=-132.585, c2=-123.386 g=-139.744\n",
      ">173, c1=-133.347, c2=-124.282 g=-141.007\n",
      ">174, c1=-133.623, c2=-124.908 g=-141.951\n",
      ">175, c1=-135.612, c2=-125.833 g=-142.939\n",
      ">176, c1=-135.866, c2=-126.522 g=-142.539\n",
      ">177, c1=-136.330, c2=-127.504 g=-144.141\n",
      ">178, c1=-137.814, c2=-128.328 g=-144.923\n",
      ">179, c1=-138.081, c2=-128.991 g=-146.245\n",
      ">180, c1=-138.602, c2=-129.722 g=-146.575\n",
      ">181, c1=-139.821, c2=-130.714 g=-147.989\n",
      ">182, c1=-140.669, c2=-131.418 g=-148.951\n",
      ">183, c1=-142.030, c2=-132.292 g=-149.779\n",
      ">184, c1=-141.839, c2=-133.225 g=-150.456\n",
      ">185, c1=-142.979, c2=-133.958 g=-151.551\n",
      ">186, c1=-143.809, c2=-134.800 g=-151.653\n",
      ">187, c1=-144.337, c2=-135.619 g=-152.134\n",
      ">188, c1=-145.258, c2=-136.455 g=-153.601\n",
      ">189, c1=-147.216, c2=-137.262 g=-154.948\n",
      ">190, c1=-146.725, c2=-138.009 g=-155.865\n",
      ">191, c1=-148.349, c2=-138.833 g=-156.440\n",
      ">192, c1=-148.697, c2=-139.712 g=-157.138\n",
      ">193, c1=-149.850, c2=-140.572 g=-158.255\n",
      ">194, c1=-150.389, c2=-141.235 g=-158.726\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: generated_plot_0194.png and model_0194.h5\n",
      ">195, c1=-151.214, c2=-142.244 g=-159.540\n",
      ">196, c1=-152.154, c2=-143.045 g=-160.433\n",
      ">197, c1=-152.767, c2=-143.880 g=-161.601\n",
      ">198, c1=-155.191, c2=-144.592 g=-162.652\n",
      ">199, c1=-154.506, c2=-145.542 g=-163.610\n",
      ">200, c1=-155.829, c2=-146.280 g=-163.699\n",
      ">201, c1=-156.859, c2=-147.143 g=-165.104\n",
      ">202, c1=-157.200, c2=-147.985 g=-166.060\n",
      ">203, c1=-157.588, c2=-148.726 g=-167.205\n",
      ">204, c1=-158.109, c2=-149.632 g=-167.740\n",
      ">205, c1=-160.735, c2=-150.542 g=-169.109\n",
      ">206, c1=-161.153, c2=-151.258 g=-169.447\n",
      ">207, c1=-160.816, c2=-152.222 g=-170.386\n",
      ">208, c1=-162.992, c2=-152.998 g=-171.451\n",
      ">209, c1=-163.793, c2=-153.859 g=-172.571\n",
      ">210, c1=-164.093, c2=-154.652 g=-173.410\n",
      ">211, c1=-164.171, c2=-155.508 g=-173.922\n",
      ">212, c1=-165.526, c2=-156.314 g=-175.177\n",
      ">213, c1=-167.078, c2=-157.196 g=-176.032\n",
      ">214, c1=-167.970, c2=-158.107 g=-176.919\n",
      ">215, c1=-168.698, c2=-158.734 g=-176.837\n",
      ">216, c1=-169.125, c2=-159.736 g=-178.763\n",
      ">217, c1=-171.211, c2=-160.618 g=-179.634\n",
      ">218, c1=-171.045, c2=-161.544 g=-180.544\n",
      ">219, c1=-172.863, c2=-162.285 g=-181.376\n",
      ">220, c1=-172.268, c2=-163.281 g=-182.268\n",
      ">221, c1=-173.173, c2=-164.039 g=-183.419\n",
      ">222, c1=-173.457, c2=-164.816 g=-182.714\n",
      ">223, c1=-175.357, c2=-165.717 g=-184.740\n",
      ">224, c1=-176.464, c2=-166.537 g=-185.678\n",
      ">225, c1=-177.747, c2=-167.367 g=-186.952\n",
      ">226, c1=-177.947, c2=-168.351 g=-188.020\n",
      ">227, c1=-178.983, c2=-169.217 g=-188.877\n",
      ">228, c1=-179.634, c2=-169.944 g=-188.524\n",
      ">229, c1=-181.114, c2=-170.895 g=-190.221\n",
      ">230, c1=-182.468, c2=-171.717 g=-190.918\n",
      ">231, c1=-183.001, c2=-172.659 g=-192.154\n",
      ">232, c1=-183.460, c2=-173.501 g=-193.359\n",
      ">233, c1=-184.098, c2=-174.440 g=-193.996\n",
      ">234, c1=-185.796, c2=-175.210 g=-195.217\n",
      ">235, c1=-186.459, c2=-176.088 g=-196.109\n",
      ">236, c1=-187.432, c2=-176.857 g=-197.248\n",
      ">237, c1=-187.817, c2=-177.624 g=-197.576\n",
      ">238, c1=-188.140, c2=-178.872 g=-199.012\n",
      ">239, c1=-190.361, c2=-179.722 g=-199.855\n",
      ">240, c1=-190.543, c2=-180.349 g=-199.782\n",
      ">241, c1=-191.593, c2=-181.454 g=-200.400\n",
      ">242, c1=-191.614, c2=-182.156 g=-202.713\n",
      ">243, c1=-193.403, c2=-183.023 g=-203.627\n",
      ">244, c1=-194.632, c2=-184.130 g=-204.763\n",
      ">245, c1=-196.152, c2=-184.939 g=-205.501\n",
      ">246, c1=-195.638, c2=-185.748 g=-205.194\n",
      ">247, c1=-197.611, c2=-186.897 g=-207.219\n",
      ">248, c1=-199.139, c2=-187.616 g=-207.242\n",
      ">249, c1=-198.455, c2=-188.538 g=-208.742\n",
      ">250, c1=-199.210, c2=-189.336 g=-209.847\n",
      ">251, c1=-200.295, c2=-190.337 g=-210.976\n",
      ">252, c1=-201.720, c2=-191.201 g=-211.892\n",
      ">253, c1=-202.933, c2=-192.104 g=-212.798\n",
      ">254, c1=-204.179, c2=-193.149 g=-213.959\n",
      ">255, c1=-204.161, c2=-193.823 g=-214.847\n",
      ">256, c1=-205.552, c2=-194.675 g=-215.670\n",
      ">257, c1=-206.682, c2=-195.740 g=-216.691\n",
      ">258, c1=-207.525, c2=-196.646 g=-217.659\n",
      ">259, c1=-207.597, c2=-197.343 g=-218.460\n",
      ">260, c1=-207.953, c2=-198.494 g=-218.919\n",
      ">261, c1=-209.307, c2=-199.173 g=-220.485\n",
      ">262, c1=-211.686, c2=-200.068 g=-221.532\n",
      ">263, c1=-211.574, c2=-201.026 g=-222.298\n",
      ">264, c1=-212.582, c2=-201.391 g=-221.944\n",
      ">265, c1=-212.624, c2=-203.004 g=-224.174\n",
      ">266, c1=-214.857, c2=-203.897 g=-225.216\n",
      ">267, c1=-215.340, c2=-204.749 g=-226.322\n",
      ">268, c1=-216.693, c2=-205.507 g=-227.336\n",
      ">269, c1=-217.176, c2=-206.515 g=-228.058\n",
      ">270, c1=-218.039, c2=-207.552 g=-228.919\n",
      ">271, c1=-219.794, c2=-208.385 g=-229.040\n",
      ">272, c1=-219.788, c2=-209.200 g=-230.370\n",
      ">273, c1=-221.193, c2=-210.112 g=-231.850\n",
      ">274, c1=-221.735, c2=-211.145 g=-232.375\n",
      ">275, c1=-224.389, c2=-212.050 g=-233.845\n",
      ">276, c1=-225.246, c2=-213.041 g=-234.778\n",
      ">277, c1=-225.486, c2=-213.391 g=-235.441\n",
      ">278, c1=-225.707, c2=-214.915 g=-236.985\n",
      ">279, c1=-227.143, c2=-215.710 g=-237.421\n",
      ">280, c1=-228.424, c2=-216.679 g=-238.660\n",
      ">281, c1=-228.821, c2=-217.580 g=-239.749\n",
      ">282, c1=-229.236, c2=-218.543 g=-240.833\n",
      ">283, c1=-231.140, c2=-219.159 g=-241.825\n",
      ">284, c1=-232.719, c2=-220.415 g=-243.011\n",
      ">285, c1=-232.756, c2=-220.967 g=-242.874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">286, c1=-234.509, c2=-222.358 g=-244.556\n",
      ">287, c1=-235.780, c2=-223.033 g=-245.889\n",
      ">288, c1=-236.180, c2=-224.121 g=-246.939\n",
      ">289, c1=-235.930, c2=-224.832 g=-247.512\n",
      ">290, c1=-238.508, c2=-226.171 g=-248.866\n",
      ">291, c1=-238.375, c2=-226.415 g=-249.778\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: generated_plot_0291.png and model_0291.h5\n",
      ">292, c1=-239.633, c2=-227.832 g=-250.167\n",
      ">293, c1=-240.930, c2=-229.021 g=-251.287\n",
      ">294, c1=-242.069, c2=-229.910 g=-252.112\n",
      ">295, c1=-241.547, c2=-230.852 g=-253.364\n",
      ">296, c1=-243.530, c2=-231.214 g=-254.435\n",
      ">297, c1=-244.628, c2=-232.825 g=-255.473\n",
      ">298, c1=-244.190, c2=-232.443 g=-256.277\n",
      ">299, c1=-246.341, c2=-234.352 g=-257.617\n",
      ">300, c1=-248.884, c2=-235.396 g=-258.699\n",
      ">301, c1=-248.021, c2=-236.275 g=-259.072\n",
      ">302, c1=-248.445, c2=-237.651 g=-260.723\n",
      ">303, c1=-250.317, c2=-238.178 g=-261.821\n",
      ">304, c1=-251.247, c2=-239.106 g=-262.895\n",
      ">305, c1=-251.987, c2=-239.756 g=-263.534\n",
      ">306, c1=-253.648, c2=-241.308 g=-264.874\n",
      ">307, c1=-254.455, c2=-242.056 g=-265.734\n",
      ">308, c1=-254.554, c2=-243.130 g=-266.868\n",
      ">309, c1=-256.410, c2=-244.185 g=-267.513\n",
      ">310, c1=-255.880, c2=-243.231 g=-266.998\n",
      ">311, c1=-257.544, c2=-246.140 g=-268.556\n",
      ">312, c1=-258.489, c2=-247.339 g=-270.399\n",
      ">313, c1=-260.007, c2=-247.937 g=-271.594\n",
      ">314, c1=-260.838, c2=-249.079 g=-272.729\n",
      ">315, c1=-262.253, c2=-250.024 g=-273.956\n",
      ">316, c1=-264.465, c2=-250.732 g=-274.975\n",
      ">317, c1=-262.990, c2=-250.618 g=-274.434\n",
      ">318, c1=-264.802, c2=-253.107 g=-276.875\n",
      ">319, c1=-265.957, c2=-253.131 g=-277.885\n",
      ">320, c1=-266.706, c2=-254.191 g=-278.682\n",
      ">321, c1=-269.058, c2=-254.514 g=-279.970\n",
      ">322, c1=-268.260, c2=-255.530 g=-280.581\n",
      ">323, c1=-269.181, c2=-257.305 g=-281.753\n",
      ">324, c1=-269.865, c2=-256.704 g=-280.405\n",
      ">325, c1=-270.558, c2=-260.041 g=-283.565\n",
      ">326, c1=-274.236, c2=-260.481 g=-284.864\n",
      ">327, c1=-273.729, c2=-259.664 g=-285.098\n",
      ">328, c1=-274.363, c2=-262.725 g=-286.853\n",
      ">329, c1=-275.437, c2=-263.289 g=-287.565\n",
      ">330, c1=-275.606, c2=-264.583 g=-288.756\n",
      ">331, c1=-277.428, c2=-264.809 g=-289.371\n",
      ">332, c1=-277.369, c2=-266.786 g=-290.556\n",
      ">333, c1=-280.279, c2=-268.074 g=-290.805\n",
      ">334, c1=-280.703, c2=-265.362 g=-292.666\n",
      ">335, c1=-280.025, c2=-267.666 g=-293.207\n",
      ">336, c1=-282.400, c2=-270.052 g=-294.627\n",
      ">337, c1=-283.462, c2=-271.369 g=-296.044\n",
      ">338, c1=-284.016, c2=-270.917 g=-296.575\n",
      ">339, c1=-285.868, c2=-272.841 g=-297.257\n",
      ">340, c1=-285.741, c2=-275.114 g=-298.823\n",
      ">341, c1=-286.845, c2=-274.174 g=-299.030\n",
      ">342, c1=-288.327, c2=-277.153 g=-300.637\n",
      ">343, c1=-287.557, c2=-274.992 g=-299.628\n",
      ">344, c1=-290.798, c2=-278.978 g=-301.536\n",
      ">345, c1=-291.602, c2=-276.262 g=-301.829\n",
      ">346, c1=-291.729, c2=-280.629 g=-304.957\n",
      ">347, c1=-294.542, c2=-280.559 g=-305.416\n",
      ">348, c1=-294.182, c2=-282.208 g=-307.203\n",
      ">349, c1=-296.511, c2=-282.193 g=-308.357\n",
      ">350, c1=-296.978, c2=-282.366 g=-309.139\n",
      ">351, c1=-296.286, c2=-282.757 g=-309.145\n",
      ">352, c1=-298.202, c2=-285.979 g=-310.488\n",
      ">353, c1=-298.282, c2=-282.509 g=-311.581\n",
      ">354, c1=-300.524, c2=-285.710 g=-311.421\n",
      ">355, c1=-301.780, c2=-289.787 g=-314.266\n",
      ">356, c1=-302.577, c2=-287.436 g=-315.212\n",
      ">357, c1=-302.274, c2=-285.450 g=-314.919\n",
      ">358, c1=-304.485, c2=-291.146 g=-317.100\n",
      ">359, c1=-304.628, c2=-289.850 g=-316.482\n",
      ">360, c1=-305.873, c2=-294.207 g=-319.096\n",
      ">361, c1=-305.906, c2=-292.750 g=-319.832\n",
      ">362, c1=-307.485, c2=-293.839 g=-320.417\n",
      ">363, c1=-309.434, c2=-288.019 g=-319.888\n",
      ">364, c1=-308.597, c2=-295.605 g=-322.256\n",
      ">365, c1=-309.892, c2=-293.526 g=-321.885\n",
      ">366, c1=-309.689, c2=-298.748 g=-324.003\n",
      ">367, c1=-312.175, c2=-300.101 g=-325.684\n",
      ">368, c1=-314.009, c2=-300.335 g=-326.787\n",
      ">369, c1=-315.006, c2=-301.287 g=-328.416\n",
      ">370, c1=-313.473, c2=-298.074 g=-328.177\n",
      ">371, c1=-314.457, c2=-303.010 g=-329.997\n",
      ">372, c1=-317.192, c2=-301.028 g=-328.557\n",
      ">373, c1=-317.734, c2=-307.254 g=-332.249\n",
      ">374, c1=-319.536, c2=-302.459 g=-331.065\n",
      ">375, c1=-319.403, c2=-309.259 g=-332.803\n",
      ">376, c1=-319.585, c2=-311.071 g=-335.372\n",
      ">377, c1=-324.167, c2=-306.845 g=-335.147\n",
      ">378, c1=-322.286, c2=-309.996 g=-335.761\n",
      ">379, c1=-325.387, c2=-312.515 g=-338.360\n",
      ">380, c1=-325.255, c2=-306.823 g=-337.323\n",
      ">381, c1=-325.537, c2=-313.497 g=-340.172\n",
      ">382, c1=-325.748, c2=-311.487 g=-337.902\n",
      ">383, c1=-328.573, c2=-316.909 g=-340.627\n",
      ">384, c1=-328.239, c2=-299.895 g=-337.893\n",
      ">385, c1=-326.889, c2=-315.522 g=-343.144\n",
      ">386, c1=-330.277, c2=-313.590 g=-343.409\n",
      ">387, c1=-328.039, c2=-314.055 g=-339.959\n",
      ">388, c1=-331.338, c2=-322.362 g=-346.716\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: generated_plot_0388.png and model_0388.h5\n",
      ">389, c1=-332.828, c2=-317.859 g=-346.888\n",
      ">390, c1=-334.241, c2=-314.642 g=-344.496\n",
      ">391, c1=-331.823, c2=-322.532 g=-349.565\n",
      ">392, c1=-332.049, c2=-314.692 g=-348.954\n",
      ">393, c1=-333.268, c2=-312.532 g=-347.698\n",
      ">394, c1=-336.659, c2=-321.864 g=-349.864\n",
      ">395, c1=-335.592, c2=-321.479 g=-350.758\n",
      ">396, c1=-337.186, c2=-324.548 g=-352.006\n",
      ">397, c1=-339.118, c2=-326.138 g=-354.239\n",
      ">398, c1=-338.076, c2=-319.865 g=-354.094\n",
      ">399, c1=-339.441, c2=-322.196 g=-353.744\n",
      ">400, c1=-337.929, c2=-324.017 g=-354.879\n",
      ">401, c1=-341.644, c2=-328.018 g=-354.626\n",
      ">402, c1=-343.620, c2=-332.465 g=-359.319\n",
      ">403, c1=-342.193, c2=-320.335 g=-356.446\n",
      ">404, c1=-340.969, c2=-332.342 g=-359.175\n",
      ">405, c1=-344.338, c2=-321.116 g=-357.456\n",
      ">406, c1=-345.588, c2=-335.192 g=-361.323\n",
      ">407, c1=-345.119, c2=-320.633 g=-358.256\n",
      ">408, c1=-346.368, c2=-336.232 g=-362.421\n",
      ">409, c1=-346.944, c2=-331.896 g=-360.617\n",
      ">410, c1=-346.952, c2=-336.989 g=-365.778\n",
      ">411, c1=-347.556, c2=-326.634 g=-361.799\n",
      ">412, c1=-348.751, c2=-336.564 g=-364.618\n",
      ">413, c1=-352.478, c2=-334.071 g=-367.488\n",
      ">414, c1=-345.934, c2=-325.568 g=-364.055\n",
      ">415, c1=-349.083, c2=-338.002 g=-369.624\n",
      ">416, c1=-349.725, c2=-317.772 g=-365.999\n",
      ">417, c1=-348.116, c2=-330.371 g=-365.330\n",
      ">418, c1=-345.031, c2=-332.964 g=-367.049\n",
      ">419, c1=-352.027, c2=-340.970 g=-371.418\n",
      ">420, c1=-350.494, c2=-335.136 g=-372.299\n",
      ">421, c1=-342.070, c2=-308.063 g=-365.199\n",
      ">422, c1=-347.178, c2=-336.154 g=-369.088\n",
      ">423, c1=-351.204, c2=-343.262 g=-374.180\n",
      ">424, c1=-354.265, c2=-337.060 g=-374.651\n",
      ">425, c1=-350.723, c2=-327.546 g=-372.480\n",
      ">426, c1=-345.612, c2=-330.527 g=-374.959\n",
      ">427, c1=-341.860, c2=-320.330 g=-371.882\n",
      ">428, c1=-351.176, c2=-338.321 g=-375.754\n",
      ">429, c1=-352.448, c2=-322.582 g=-374.153\n",
      ">430, c1=-344.919, c2=-324.463 g=-373.461\n",
      ">431, c1=-345.112, c2=-316.700 g=-372.288\n",
      ">432, c1=-322.627, c2=-298.694 g=-366.613\n",
      ">433, c1=-333.216, c2=-304.190 g=-367.344\n",
      ">434, c1=-326.482, c2=-300.920 g=-363.588\n",
      ">435, c1=-312.615, c2=-271.191 g=-359.694\n",
      ">436, c1=-304.646, c2=-265.683 g=-358.784\n",
      ">437, c1=-242.131, c2=-172.823 g=-343.452\n",
      ">438, c1=-207.154, c2=-150.239 g=-329.862\n",
      ">439, c1=-195.199, c2=-167.455 g=-327.494\n",
      ">440, c1=-144.308, c2=-90.912 g=-308.270\n",
      ">441, c1=-99.257, c2=-31.397 g=-276.012\n",
      ">442, c1=-12.083, c2=54.550 g=-208.524\n",
      ">443, c1=-50.503, c2=85.625 g=-162.123\n",
      ">444, c1=-48.645, c2=82.512 g=-133.880\n",
      ">445, c1=-51.308, c2=80.870 g=-118.823\n",
      ">446, c1=-57.404, c2=71.393 g=-110.958\n",
      ">447, c1=-65.693, c2=64.805 g=-106.184\n",
      ">448, c1=-65.464, c2=56.868 g=-98.045\n",
      ">449, c1=-74.052, c2=47.321 g=-92.524\n",
      ">450, c1=-82.430, c2=39.627 g=-95.535\n",
      ">451, c1=-84.597, c2=35.237 g=-91.059\n",
      ">452, c1=-95.247, c2=29.070 g=-98.748\n",
      ">453, c1=-103.645, c2=22.389 g=-106.609\n",
      ">454, c1=-101.284, c2=16.845 g=-110.289\n",
      ">455, c1=-113.583, c2=4.582 g=-127.707\n",
      ">456, c1=-118.255, c2=-6.560 g=-143.142\n",
      ">457, c1=-135.182, c2=-31.682 g=-161.723\n",
      ">458, c1=-144.573, c2=-52.950 g=-183.795\n",
      ">459, c1=-154.996, c2=-83.523 g=-199.949\n",
      ">460, c1=-164.333, c2=-105.273 g=-219.329\n",
      ">461, c1=-151.406, c2=-123.709 g=-227.371\n",
      ">462, c1=-168.639, c2=-142.370 g=-236.012\n",
      ">463, c1=-179.794, c2=-156.556 g=-243.249\n",
      ">464, c1=-175.863, c2=-152.347 g=-249.747\n",
      ">465, c1=-171.466, c2=-155.074 g=-250.006\n",
      ">466, c1=-171.022, c2=-155.334 g=-252.711\n",
      ">467, c1=-178.488, c2=-156.066 g=-255.520\n",
      ">468, c1=-155.315, c2=-147.698 g=-254.759\n",
      ">469, c1=-171.865, c2=-138.468 g=-254.701\n",
      ">470, c1=-158.000, c2=-130.861 g=-252.929\n",
      ">471, c1=-158.357, c2=-123.543 g=-251.481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">472, c1=-145.818, c2=-106.532 g=-247.048\n",
      ">473, c1=-149.643, c2=-89.234 g=-245.122\n",
      ">474, c1=-141.190, c2=-80.693 g=-240.359\n",
      ">475, c1=-130.285, c2=-50.678 g=-238.293\n",
      ">476, c1=-161.438, c2=-46.401 g=-239.977\n",
      ">477, c1=-148.432, c2=-29.539 g=-235.266\n",
      ">478, c1=-175.954, c2=-17.235 g=-232.610\n",
      ">479, c1=-172.388, c2=-8.353 g=-230.851\n",
      ">480, c1=-171.597, c2=-3.017 g=-226.688\n",
      ">481, c1=-190.138, c2=-2.772 g=-221.818\n",
      ">482, c1=-189.867, c2=-9.961 g=-221.929\n",
      ">483, c1=-205.807, c2=-18.169 g=-215.964\n",
      ">484, c1=-213.238, c2=-27.627 g=-211.015\n",
      ">485, c1=-224.922, c2=-41.462 g=-196.459\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: generated_plot_0485.png and model_0485.h5\n",
      ">486, c1=-234.496, c2=-60.799 g=-179.119\n",
      ">487, c1=-250.077, c2=-79.927 g=-164.916\n",
      ">488, c1=-260.834, c2=-102.144 g=-146.206\n",
      ">489, c1=-270.966, c2=-124.489 g=-128.367\n",
      ">490, c1=-278.590, c2=-145.649 g=-106.447\n",
      ">491, c1=-289.034, c2=-167.929 g=-90.623\n",
      ">492, c1=-302.353, c2=-183.683 g=-72.974\n",
      ">493, c1=-301.804, c2=-198.379 g=-57.013\n",
      ">494, c1=-306.836, c2=-213.169 g=-31.067\n",
      ">495, c1=-312.868, c2=-227.596 g=-6.138\n",
      ">496, c1=-320.043, c2=-240.517 g=13.286\n",
      ">497, c1=-322.616, c2=-252.092 g=34.312\n",
      ">498, c1=-326.787, c2=-262.925 g=56.298\n",
      ">499, c1=-331.524, c2=-267.502 g=68.919\n",
      ">500, c1=-337.981, c2=-277.934 g=84.580\n",
      ">501, c1=-346.660, c2=-284.219 g=103.166\n",
      ">502, c1=-345.483, c2=-293.806 g=128.634\n",
      ">503, c1=-356.093, c2=-301.211 g=153.722\n",
      ">504, c1=-359.230, c2=-310.090 g=185.901\n",
      ">505, c1=-366.855, c2=-318.919 g=217.788\n",
      ">506, c1=-373.559, c2=-326.846 g=238.085\n",
      ">507, c1=-378.461, c2=-333.444 g=259.453\n",
      ">508, c1=-381.912, c2=-340.329 g=274.065\n",
      ">509, c1=-387.219, c2=-345.155 g=287.170\n",
      ">510, c1=-393.245, c2=-353.205 g=297.788\n",
      ">511, c1=-396.962, c2=-358.224 g=304.031\n",
      ">512, c1=-400.065, c2=-363.212 g=311.335\n",
      ">513, c1=-403.439, c2=-369.465 g=315.623\n",
      ">514, c1=-407.694, c2=-374.188 g=320.898\n",
      ">515, c1=-411.169, c2=-378.016 g=325.597\n",
      ">516, c1=-412.975, c2=-381.470 g=328.727\n",
      ">517, c1=-415.384, c2=-385.187 g=331.886\n",
      ">518, c1=-419.723, c2=-388.203 g=336.479\n",
      ">519, c1=-422.123, c2=-389.925 g=338.895\n",
      ">520, c1=-424.471, c2=-391.059 g=342.496\n",
      ">521, c1=-426.491, c2=-394.169 g=346.606\n",
      ">522, c1=-427.066, c2=-395.551 g=348.279\n",
      ">523, c1=-430.159, c2=-396.336 g=351.034\n",
      ">524, c1=-432.585, c2=-399.257 g=355.247\n",
      ">525, c1=-433.243, c2=-399.250 g=356.882\n",
      ">526, c1=-435.538, c2=-400.266 g=359.022\n",
      ">527, c1=-437.213, c2=-400.776 g=362.130\n",
      ">528, c1=-439.258, c2=-402.555 g=366.570\n",
      ">529, c1=-439.677, c2=-404.987 g=369.425\n",
      ">530, c1=-443.234, c2=-405.950 g=374.004\n",
      ">531, c1=-444.009, c2=-408.479 g=378.033\n",
      ">532, c1=-445.286, c2=-410.575 g=381.570\n",
      ">533, c1=-447.473, c2=-414.141 g=385.859\n",
      ">534, c1=-449.579, c2=-416.286 g=390.513\n",
      ">535, c1=-451.632, c2=-418.096 g=392.853\n",
      ">536, c1=-453.831, c2=-420.177 g=397.236\n",
      ">537, c1=-454.399, c2=-422.917 g=400.959\n",
      ">538, c1=-458.227, c2=-424.469 g=403.638\n",
      ">539, c1=-459.540, c2=-426.604 g=408.655\n",
      ">540, c1=-462.062, c2=-428.815 g=412.214\n",
      ">541, c1=-463.999, c2=-429.956 g=414.665\n",
      ">542, c1=-464.794, c2=-431.292 g=418.242\n",
      ">543, c1=-466.449, c2=-432.999 g=421.352\n",
      ">544, c1=-469.976, c2=-434.991 g=424.928\n",
      ">545, c1=-470.740, c2=-436.852 g=427.217\n",
      ">546, c1=-473.263, c2=-437.224 g=430.784\n",
      ">547, c1=-473.997, c2=-440.351 g=433.069\n",
      ">548, c1=-477.176, c2=-442.195 g=435.655\n",
      ">549, c1=-479.155, c2=-443.621 g=438.515\n",
      ">550, c1=-480.947, c2=-445.481 g=440.581\n",
      ">551, c1=-481.776, c2=-447.234 g=442.408\n",
      ">552, c1=-486.196, c2=-448.788 g=444.248\n",
      ">553, c1=-486.250, c2=-450.349 g=445.812\n",
      ">554, c1=-487.830, c2=-451.204 g=447.451\n",
      ">555, c1=-491.066, c2=-453.057 g=449.104\n",
      ">556, c1=-490.945, c2=-454.334 g=451.206\n",
      ">557, c1=-494.586, c2=-455.332 g=452.005\n",
      ">558, c1=-495.107, c2=-456.429 g=453.994\n",
      ">559, c1=-498.708, c2=-457.266 g=454.695\n",
      ">560, c1=-499.000, c2=-459.039 g=456.267\n",
      ">561, c1=-500.275, c2=-459.454 g=457.471\n",
      ">562, c1=-501.242, c2=-460.108 g=458.245\n",
      ">563, c1=-505.243, c2=-461.010 g=459.813\n",
      ">564, c1=-505.570, c2=-462.077 g=460.518\n",
      ">565, c1=-507.547, c2=-463.047 g=461.909\n",
      ">566, c1=-509.008, c2=-464.645 g=463.029\n",
      ">567, c1=-510.548, c2=-465.602 g=464.586\n",
      ">568, c1=-511.856, c2=-466.527 g=466.201\n",
      ">569, c1=-513.655, c2=-467.795 g=467.369\n",
      ">570, c1=-515.557, c2=-468.901 g=468.604\n",
      ">571, c1=-516.537, c2=-470.161 g=469.727\n",
      ">572, c1=-517.643, c2=-471.474 g=471.019\n",
      ">573, c1=-519.242, c2=-472.618 g=472.454\n",
      ">574, c1=-520.528, c2=-473.949 g=473.753\n",
      ">575, c1=-522.217, c2=-475.205 g=475.091\n",
      ">576, c1=-524.322, c2=-476.414 g=476.318\n",
      ">577, c1=-526.200, c2=-477.619 g=477.616\n",
      ">578, c1=-525.735, c2=-478.913 g=478.972\n",
      ">579, c1=-527.892, c2=-480.231 g=480.315\n",
      ">580, c1=-530.810, c2=-481.387 g=481.486\n",
      ">581, c1=-530.811, c2=-482.639 g=482.850\n",
      ">582, c1=-532.677, c2=-483.975 g=484.061\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: generated_plot_0582.png and model_0582.h5\n",
      ">583, c1=-532.840, c2=-485.135 g=485.439\n",
      ">584, c1=-534.731, c2=-486.492 g=486.674\n",
      ">585, c1=-537.243, c2=-487.691 g=487.954\n",
      ">586, c1=-539.349, c2=-488.849 g=489.186\n",
      ">587, c1=-539.037, c2=-490.135 g=490.441\n",
      ">588, c1=-539.402, c2=-491.150 g=491.603\n",
      ">589, c1=-541.872, c2=-492.481 g=492.927\n",
      ">590, c1=-543.499, c2=-493.504 g=494.139\n",
      ">591, c1=-544.916, c2=-494.753 g=495.288\n",
      ">592, c1=-546.904, c2=-495.853 g=496.454\n",
      ">593, c1=-546.785, c2=-497.140 g=497.343\n",
      ">594, c1=-548.103, c2=-498.027 g=498.719\n",
      ">595, c1=-550.098, c2=-498.713 g=499.962\n",
      ">596, c1=-552.409, c2=-500.308 g=501.098\n",
      ">597, c1=-552.114, c2=-501.525 g=502.453\n",
      ">598, c1=-552.586, c2=-502.902 g=503.606\n",
      ">599, c1=-555.089, c2=-504.641 g=504.946\n",
      ">600, c1=-556.407, c2=-505.860 g=505.973\n",
      ">601, c1=-558.055, c2=-506.967 g=507.237\n",
      ">602, c1=-559.961, c2=-508.005 g=508.355\n",
      ">603, c1=-560.500, c2=-509.309 g=509.628\n",
      ">604, c1=-562.683, c2=-510.515 g=510.799\n",
      ">605, c1=-564.299, c2=-511.569 g=511.931\n",
      ">606, c1=-563.653, c2=-512.822 g=513.171\n",
      ">607, c1=-565.261, c2=-514.226 g=514.589\n",
      ">608, c1=-567.977, c2=-515.259 g=515.553\n",
      ">609, c1=-568.019, c2=-516.546 g=516.849\n",
      ">610, c1=-570.610, c2=-517.805 g=517.916\n",
      ">611, c1=-571.468, c2=-518.994 g=519.225\n",
      ">612, c1=-573.253, c2=-520.018 g=520.495\n",
      ">613, c1=-573.046, c2=-521.405 g=521.757\n",
      ">614, c1=-575.939, c2=-522.479 g=522.894\n",
      ">615, c1=-576.427, c2=-523.682 g=524.108\n",
      ">616, c1=-578.101, c2=-524.869 g=525.439\n",
      ">617, c1=-578.221, c2=-526.105 g=526.518\n",
      ">618, c1=-580.592, c2=-527.214 g=527.870\n",
      ">619, c1=-581.455, c2=-528.524 g=528.977\n",
      ">620, c1=-585.484, c2=-529.758 g=530.299\n",
      ">621, c1=-585.115, c2=-530.851 g=531.497\n",
      ">622, c1=-585.270, c2=-532.262 g=532.711\n",
      ">623, c1=-587.312, c2=-533.388 g=533.912\n",
      ">624, c1=-588.703, c2=-534.499 g=535.077\n",
      ">625, c1=-591.117, c2=-535.772 g=536.293\n",
      ">626, c1=-592.022, c2=-536.729 g=537.410\n",
      ">627, c1=-593.080, c2=-537.836 g=538.741\n",
      ">628, c1=-594.522, c2=-539.148 g=539.886\n",
      ">629, c1=-595.383, c2=-540.474 g=541.137\n",
      ">630, c1=-595.851, c2=-541.385 g=542.255\n",
      ">631, c1=-598.560, c2=-542.415 g=543.270\n",
      ">632, c1=-599.431, c2=-543.451 g=544.496\n",
      ">633, c1=-601.129, c2=-544.712 g=545.651\n",
      ">634, c1=-602.686, c2=-545.686 g=546.755\n",
      ">635, c1=-602.208, c2=-546.810 g=547.984\n",
      ">636, c1=-605.043, c2=-547.944 g=549.126\n",
      ">637, c1=-606.088, c2=-549.406 g=550.270\n",
      ">638, c1=-606.246, c2=-550.151 g=551.462\n",
      ">639, c1=-608.538, c2=-551.691 g=552.614\n",
      ">640, c1=-610.092, c2=-552.384 g=553.780\n",
      ">641, c1=-610.968, c2=-553.318 g=555.054\n",
      ">642, c1=-613.218, c2=-555.058 g=556.336\n",
      ">643, c1=-614.742, c2=-556.497 g=557.473\n",
      ">644, c1=-614.403, c2=-557.289 g=558.365\n",
      ">645, c1=-616.787, c2=-558.208 g=559.750\n",
      ">646, c1=-617.143, c2=-559.645 g=560.911\n",
      ">647, c1=-619.157, c2=-560.801 g=562.222\n",
      ">648, c1=-619.735, c2=-562.496 g=563.402\n",
      ">649, c1=-622.638, c2=-563.483 g=564.649\n",
      ">650, c1=-622.679, c2=-564.348 g=565.910\n",
      ">651, c1=-624.949, c2=-566.145 g=567.077\n",
      ">652, c1=-625.979, c2=-567.571 g=568.322\n",
      ">653, c1=-627.234, c2=-568.993 g=569.578\n",
      ">654, c1=-628.336, c2=-570.182 g=570.875\n",
      ">655, c1=-629.753, c2=-571.856 g=572.273\n",
      ">656, c1=-631.024, c2=-572.990 g=573.557\n",
      ">657, c1=-632.684, c2=-574.175 g=574.734\n",
      ">658, c1=-634.620, c2=-575.465 g=575.972\n",
      ">659, c1=-634.053, c2=-576.668 g=577.145\n",
      ">660, c1=-634.482, c2=-578.065 g=578.556\n",
      ">661, c1=-638.689, c2=-579.133 g=579.770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">662, c1=-638.455, c2=-580.440 g=581.040\n",
      ">663, c1=-642.512, c2=-581.733 g=582.273\n",
      ">664, c1=-641.264, c2=-582.898 g=583.649\n",
      ">665, c1=-644.549, c2=-584.234 g=584.803\n",
      ">666, c1=-644.551, c2=-585.542 g=586.060\n",
      ">667, c1=-647.078, c2=-586.680 g=587.242\n",
      ">668, c1=-647.577, c2=-587.871 g=588.608\n",
      ">669, c1=-648.541, c2=-589.158 g=589.794\n",
      ">670, c1=-651.070, c2=-590.507 g=591.072\n",
      ">671, c1=-651.885, c2=-591.627 g=592.353\n",
      ">672, c1=-653.839, c2=-592.881 g=593.598\n",
      ">673, c1=-655.701, c2=-594.208 g=594.864\n",
      ">674, c1=-656.506, c2=-595.441 g=596.120\n",
      ">675, c1=-658.183, c2=-596.722 g=597.351\n",
      ">676, c1=-658.319, c2=-597.938 g=598.602\n",
      ">677, c1=-660.343, c2=-599.117 g=599.839\n",
      ">678, c1=-659.833, c2=-600.411 g=601.127\n",
      ">679, c1=-664.141, c2=-601.510 g=602.406\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: generated_plot_0679.png and model_0679.h5\n",
      ">680, c1=-665.050, c2=-602.867 g=603.594\n",
      ">681, c1=-665.068, c2=-604.062 g=604.888\n",
      ">682, c1=-668.164, c2=-605.204 g=606.047\n",
      ">683, c1=-669.626, c2=-606.502 g=607.265\n",
      ">684, c1=-671.871, c2=-607.564 g=608.477\n",
      ">685, c1=-670.848, c2=-608.730 g=609.758\n",
      ">686, c1=-673.432, c2=-610.156 g=610.971\n",
      ">687, c1=-674.413, c2=-611.288 g=612.130\n",
      ">688, c1=-676.341, c2=-612.595 g=613.421\n",
      ">689, c1=-677.105, c2=-613.600 g=614.598\n",
      ">690, c1=-678.608, c2=-614.867 g=616.037\n",
      ">691, c1=-678.519, c2=-616.245 g=617.132\n",
      ">692, c1=-681.495, c2=-617.557 g=618.369\n",
      ">693, c1=-683.231, c2=-618.711 g=619.554\n",
      ">694, c1=-682.760, c2=-619.626 g=620.774\n",
      ">695, c1=-685.730, c2=-620.816 g=621.915\n",
      ">696, c1=-687.003, c2=-621.776 g=623.134\n",
      ">697, c1=-687.558, c2=-622.670 g=624.241\n",
      ">698, c1=-689.468, c2=-622.682 g=625.233\n",
      ">699, c1=-690.287, c2=-622.048 g=626.147\n",
      ">700, c1=-691.846, c2=-621.604 g=627.145\n",
      ">701, c1=-692.851, c2=-621.105 g=627.021\n",
      ">702, c1=-693.038, c2=-613.900 g=627.319\n",
      ">703, c1=-694.886, c2=-606.853 g=627.368\n",
      ">704, c1=-694.236, c2=-600.577 g=625.465\n",
      ">705, c1=-694.497, c2=-591.359 g=625.024\n",
      ">706, c1=-694.545, c2=-584.117 g=622.754\n",
      ">707, c1=-694.449, c2=-580.886 g=620.598\n",
      ">708, c1=-695.640, c2=-573.139 g=619.416\n",
      ">709, c1=-695.134, c2=-582.106 g=617.360\n",
      ">710, c1=-695.440, c2=-580.558 g=614.812\n",
      ">711, c1=-696.357, c2=-586.718 g=617.248\n",
      ">712, c1=-697.493, c2=-593.722 g=617.500\n",
      ">713, c1=-698.278, c2=-602.607 g=622.641\n",
      ">714, c1=-700.303, c2=-610.399 g=623.384\n",
      ">715, c1=-701.463, c2=-617.062 g=625.181\n",
      ">716, c1=-704.154, c2=-619.806 g=629.171\n",
      ">717, c1=-703.206, c2=-626.062 g=631.825\n",
      ">718, c1=-706.801, c2=-630.365 g=633.913\n",
      ">719, c1=-708.730, c2=-632.718 g=638.051\n",
      ">720, c1=-709.802, c2=-636.334 g=639.302\n",
      ">721, c1=-712.079, c2=-638.128 g=641.367\n",
      ">722, c1=-714.725, c2=-641.906 g=643.688\n",
      ">723, c1=-715.347, c2=-645.182 g=647.091\n",
      ">724, c1=-716.933, c2=-645.485 g=648.292\n",
      ">725, c1=-718.320, c2=-647.152 g=651.075\n",
      ">726, c1=-719.719, c2=-648.594 g=651.683\n",
      ">727, c1=-722.269, c2=-651.145 g=654.112\n",
      ">728, c1=-724.053, c2=-653.063 g=656.413\n",
      ">729, c1=-724.506, c2=-653.292 g=656.423\n",
      ">730, c1=-726.740, c2=-654.903 g=659.036\n",
      ">731, c1=-728.817, c2=-657.967 g=661.066\n",
      ">732, c1=-730.462, c2=-659.686 g=662.129\n",
      ">733, c1=-732.224, c2=-659.341 g=663.406\n",
      ">734, c1=-733.337, c2=-661.235 g=665.855\n",
      ">735, c1=-733.963, c2=-660.908 g=666.019\n",
      ">736, c1=-735.909, c2=-661.537 g=666.474\n",
      ">737, c1=-738.681, c2=-661.444 g=667.107\n",
      ">738, c1=-737.770, c2=-656.245 g=666.527\n",
      ">739, c1=-739.937, c2=-652.785 g=664.992\n",
      ">740, c1=-740.940, c2=-650.818 g=662.677\n",
      ">741, c1=-740.871, c2=-646.851 g=660.342\n",
      ">742, c1=-742.382, c2=-650.400 g=661.891\n",
      ">743, c1=-743.988, c2=-651.680 g=663.413\n",
      ">744, c1=-743.609, c2=-645.578 g=662.680\n",
      ">745, c1=-744.669, c2=-641.589 g=663.923\n",
      ">746, c1=-742.469, c2=-639.223 g=665.590\n",
      ">747, c1=-742.203, c2=-626.491 g=665.072\n",
      ">748, c1=-741.423, c2=-632.263 g=666.345\n",
      ">749, c1=-739.037, c2=-608.283 g=659.589\n",
      ">750, c1=-736.019, c2=-603.035 g=659.968\n",
      ">751, c1=-737.850, c2=-609.435 g=658.464\n",
      ">752, c1=-736.002, c2=-563.819 g=642.734\n",
      ">753, c1=-727.638, c2=-575.256 g=642.960\n",
      ">754, c1=-723.620, c2=-561.946 g=633.094\n",
      ">755, c1=-723.166, c2=-580.118 g=630.887\n",
      ">756, c1=-720.503, c2=-568.338 g=627.897\n",
      ">757, c1=-715.689, c2=-572.857 g=625.026\n",
      ">758, c1=-722.225, c2=-592.205 g=622.842\n",
      ">759, c1=-721.627, c2=-607.085 g=632.340\n",
      ">760, c1=-728.198, c2=-611.738 g=636.480\n",
      ">761, c1=-730.458, c2=-621.504 g=641.894\n",
      ">762, c1=-735.488, c2=-631.029 g=646.535\n",
      ">763, c1=-737.391, c2=-641.731 g=655.707\n",
      ">764, c1=-744.592, c2=-647.537 g=656.860\n",
      ">765, c1=-746.213, c2=-654.856 g=663.117\n",
      ">766, c1=-750.361, c2=-660.730 g=673.800\n",
      ">767, c1=-755.301, c2=-667.770 g=677.589\n",
      ">768, c1=-759.934, c2=-674.045 g=681.539\n",
      ">769, c1=-764.365, c2=-678.333 g=687.003\n",
      ">770, c1=-767.161, c2=-679.913 g=687.256\n",
      ">771, c1=-768.198, c2=-686.764 g=694.015\n",
      ">772, c1=-770.895, c2=-688.638 g=696.454\n",
      ">773, c1=-775.056, c2=-692.815 g=699.516\n",
      ">774, c1=-776.117, c2=-694.227 g=700.103\n",
      ">775, c1=-776.820, c2=-698.207 g=704.565\n",
      ">776, c1=-780.632, c2=-700.743 g=707.857\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: generated_plot_0776.png and model_0776.h5\n",
      ">777, c1=-782.634, c2=-702.058 g=707.331\n",
      ">778, c1=-784.378, c2=-704.170 g=709.514\n",
      ">779, c1=-785.615, c2=-704.668 g=711.116\n",
      ">780, c1=-787.114, c2=-704.361 g=711.089\n",
      ">781, c1=-789.840, c2=-705.595 g=714.585\n",
      ">782, c1=-789.958, c2=-707.838 g=715.652\n",
      ">783, c1=-793.582, c2=-706.998 g=715.847\n",
      ">784, c1=-794.612, c2=-709.128 g=718.024\n",
      ">785, c1=-796.563, c2=-708.187 g=718.361\n",
      ">786, c1=-796.571, c2=-710.538 g=720.029\n",
      ">787, c1=-798.233, c2=-709.082 g=720.918\n",
      ">788, c1=-799.766, c2=-712.221 g=721.400\n",
      ">789, c1=-800.754, c2=-708.932 g=720.756\n",
      ">790, c1=-801.657, c2=-709.174 g=720.658\n",
      ">791, c1=-801.888, c2=-709.323 g=721.960\n",
      ">792, c1=-804.817, c2=-704.890 g=719.479\n",
      ">793, c1=-804.370, c2=-706.521 g=719.757\n",
      ">794, c1=-805.445, c2=-701.018 g=717.646\n",
      ">795, c1=-805.876, c2=-698.461 g=720.763\n",
      ">796, c1=-806.471, c2=-691.770 g=717.147\n",
      ">797, c1=-803.048, c2=-690.326 g=718.173\n",
      ">798, c1=-803.708, c2=-680.874 g=717.589\n",
      ">799, c1=-803.190, c2=-668.665 g=715.497\n",
      ">800, c1=-803.566, c2=-669.335 g=707.795\n",
      ">801, c1=-802.081, c2=-662.209 g=707.238\n",
      ">802, c1=-799.033, c2=-641.709 g=699.544\n",
      ">803, c1=-795.060, c2=-616.746 g=696.718\n",
      ">804, c1=-792.271, c2=-620.241 g=689.441\n",
      ">805, c1=-791.025, c2=-622.582 g=688.174\n",
      ">806, c1=-793.799, c2=-614.702 g=667.408\n",
      ">807, c1=-794.251, c2=-603.457 g=668.017\n",
      ">808, c1=-791.856, c2=-600.046 g=651.775\n",
      ">809, c1=-792.295, c2=-609.864 g=648.965\n",
      ">810, c1=-792.889, c2=-595.368 g=637.502\n",
      ">811, c1=-798.040, c2=-603.877 g=645.283\n",
      ">812, c1=-798.772, c2=-605.286 g=635.272\n",
      ">813, c1=-801.104, c2=-600.352 g=639.292\n",
      ">814, c1=-803.295, c2=-607.086 g=634.878\n",
      ">815, c1=-807.929, c2=-610.318 g=633.558\n",
      ">816, c1=-811.819, c2=-613.318 g=639.192\n",
      ">817, c1=-814.309, c2=-621.413 g=641.774\n",
      ">818, c1=-816.572, c2=-631.121 g=647.483\n",
      ">819, c1=-818.933, c2=-637.563 g=652.667\n",
      ">820, c1=-820.586, c2=-643.558 g=657.536\n",
      ">821, c1=-820.005, c2=-653.853 g=664.301\n",
      ">822, c1=-822.963, c2=-659.498 g=670.867\n",
      ">823, c1=-826.586, c2=-666.852 g=680.169\n",
      ">824, c1=-828.681, c2=-677.598 g=684.371\n",
      ">825, c1=-830.113, c2=-683.173 g=690.231\n",
      ">826, c1=-829.147, c2=-687.794 g=694.939\n",
      ">827, c1=-833.826, c2=-693.084 g=699.922\n",
      ">828, c1=-837.022, c2=-698.274 g=703.469\n",
      ">829, c1=-835.843, c2=-700.924 g=706.432\n",
      ">830, c1=-838.548, c2=-703.787 g=709.902\n",
      ">831, c1=-840.140, c2=-706.163 g=715.057\n",
      ">832, c1=-841.433, c2=-712.694 g=716.841\n",
      ">833, c1=-842.530, c2=-713.082 g=718.389\n",
      ">834, c1=-841.981, c2=-716.129 g=723.312\n",
      ">835, c1=-842.042, c2=-716.995 g=724.084\n",
      ">836, c1=-842.263, c2=-714.736 g=729.605\n",
      ">837, c1=-843.828, c2=-715.868 g=728.217\n",
      ">838, c1=-840.924, c2=-713.660 g=732.321\n",
      ">839, c1=-842.810, c2=-711.947 g=728.164\n",
      ">840, c1=-839.196, c2=-701.752 g=732.194\n",
      ">841, c1=-839.017, c2=-697.730 g=732.200\n",
      ">842, c1=-835.220, c2=-685.804 g=729.895\n",
      ">843, c1=-834.663, c2=-675.447 g=731.883\n",
      ">844, c1=-829.291, c2=-678.287 g=735.706\n",
      ">845, c1=-826.460, c2=-665.833 g=730.875\n",
      ">846, c1=-830.341, c2=-680.378 g=734.763\n",
      ">847, c1=-821.781, c2=-657.552 g=737.037\n",
      ">848, c1=-823.379, c2=-667.561 g=732.688\n",
      ">849, c1=-820.955, c2=-644.201 g=721.798\n",
      ">850, c1=-809.521, c2=-622.758 g=722.068\n",
      ">851, c1=-805.460, c2=-622.148 g=725.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">852, c1=-803.691, c2=-623.237 g=715.546\n",
      ">853, c1=-804.373, c2=-596.352 g=711.374\n",
      ">854, c1=-796.610, c2=-596.189 g=712.134\n",
      ">855, c1=-798.841, c2=-614.183 g=711.085\n",
      ">856, c1=-796.455, c2=-621.378 g=704.485\n",
      ">857, c1=-805.243, c2=-633.766 g=717.746\n",
      ">858, c1=-812.558, c2=-638.248 g=718.208\n",
      ">859, c1=-814.821, c2=-659.634 g=717.603\n",
      ">860, c1=-814.263, c2=-655.687 g=725.210\n",
      ">861, c1=-823.171, c2=-670.039 g=721.903\n",
      ">862, c1=-824.411, c2=-676.414 g=720.409\n",
      ">863, c1=-827.771, c2=-680.457 g=726.240\n",
      ">864, c1=-828.871, c2=-679.207 g=722.905\n",
      ">865, c1=-832.367, c2=-689.327 g=726.625\n",
      ">866, c1=-837.384, c2=-690.169 g=723.736\n",
      ">867, c1=-836.532, c2=-684.189 g=722.266\n",
      ">868, c1=-837.261, c2=-689.064 g=715.557\n",
      ">869, c1=-841.679, c2=-681.140 g=712.490\n",
      ">870, c1=-842.167, c2=-676.179 g=706.780\n",
      ">871, c1=-839.988, c2=-680.924 g=701.865\n",
      ">872, c1=-840.882, c2=-685.412 g=696.867\n",
      ">873, c1=-841.908, c2=-692.120 g=701.219\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: generated_plot_0873.png and model_0873.h5\n",
      ">874, c1=-839.403, c2=-697.846 g=699.252\n",
      ">875, c1=-843.936, c2=-708.826 g=700.654\n",
      ">876, c1=-842.859, c2=-705.037 g=699.955\n",
      ">877, c1=-843.905, c2=-709.032 g=693.180\n",
      ">878, c1=-843.229, c2=-714.909 g=688.743\n",
      ">879, c1=-844.183, c2=-710.244 g=689.235\n",
      ">880, c1=-840.810, c2=-708.828 g=694.964\n",
      ">881, c1=-836.844, c2=-711.423 g=695.234\n",
      ">882, c1=-842.412, c2=-715.498 g=693.641\n",
      ">883, c1=-844.997, c2=-715.337 g=694.233\n",
      ">884, c1=-848.740, c2=-717.949 g=699.338\n",
      ">885, c1=-851.196, c2=-725.853 g=699.324\n",
      ">886, c1=-852.204, c2=-736.593 g=693.295\n",
      ">887, c1=-856.382, c2=-732.350 g=682.298\n",
      ">888, c1=-857.424, c2=-724.540 g=658.972\n",
      ">889, c1=-853.625, c2=-718.031 g=615.135\n",
      ">890, c1=-845.684, c2=-694.494 g=557.906\n",
      ">891, c1=-838.632, c2=-632.867 g=536.265\n",
      ">892, c1=-826.310, c2=-630.402 g=500.253\n",
      ">893, c1=-817.227, c2=-624.623 g=499.295\n",
      ">894, c1=-810.158, c2=-628.097 g=455.870\n",
      ">895, c1=-805.062, c2=-610.240 g=269.528\n",
      ">896, c1=-783.757, c2=-533.642 g=-52.161\n",
      ">897, c1=-751.828, c2=-365.586 g=-281.113\n",
      ">898, c1=-698.491, c2=-159.572 g=-354.371\n",
      ">899, c1=-641.486, c2=-117.833 g=-369.665\n",
      ">900, c1=-611.766, c2=-31.192 g=-404.780\n",
      ">901, c1=-586.903, c2=-24.241 g=-414.681\n",
      ">902, c1=-574.259, c2=-28.217 g=-429.938\n",
      ">903, c1=-566.772, c2=57.963 g=-439.082\n",
      ">904, c1=-557.451, c2=46.051 g=-446.359\n",
      ">905, c1=-550.746, c2=53.059 g=-448.364\n",
      ">906, c1=-556.812, c2=36.640 g=-455.909\n",
      ">907, c1=-528.411, c2=44.530 g=-464.986\n",
      ">908, c1=-562.302, c2=61.831 g=-465.481\n",
      ">909, c1=-527.746, c2=-27.522 g=-487.895\n",
      ">910, c1=-533.424, c2=-43.056 g=-519.934\n",
      ">911, c1=-558.754, c2=-46.030 g=-518.431\n",
      ">912, c1=-539.434, c2=-69.353 g=-533.454\n",
      ">913, c1=-544.935, c2=-112.385 g=-532.462\n",
      ">914, c1=-535.116, c2=-101.355 g=-543.593\n",
      ">915, c1=-520.169, c2=-80.124 g=-517.771\n",
      ">916, c1=-519.973, c2=-155.465 g=-521.150\n",
      ">917, c1=-539.741, c2=-180.250 g=-526.385\n",
      ">918, c1=-514.081, c2=-150.744 g=-513.857\n",
      ">919, c1=-523.399, c2=-143.562 g=-524.635\n",
      ">920, c1=-495.300, c2=-66.006 g=-505.405\n",
      ">921, c1=-479.756, c2=68.378 g=-489.139\n",
      ">922, c1=-484.554, c2=22.918 g=-494.942\n",
      ">923, c1=-471.911, c2=56.371 g=-478.942\n",
      ">924, c1=-475.970, c2=134.891 g=-454.968\n",
      ">925, c1=-443.213, c2=157.714 g=-409.915\n",
      ">926, c1=-465.769, c2=167.792 g=-391.687\n",
      ">927, c1=-447.159, c2=184.364 g=-345.978\n",
      ">928, c1=-437.574, c2=185.347 g=-310.567\n",
      ">929, c1=-434.771, c2=180.775 g=-286.511\n",
      ">930, c1=-420.016, c2=115.927 g=-233.656\n",
      ">931, c1=-396.148, c2=110.446 g=-201.655\n",
      ">932, c1=-396.126, c2=113.359 g=-164.491\n",
      ">933, c1=-386.424, c2=108.334 g=-104.096\n",
      ">934, c1=-392.016, c2=95.384 g=-81.455\n",
      ">935, c1=-384.090, c2=58.058 g=-111.827\n",
      ">936, c1=-393.184, c2=93.452 g=-107.559\n",
      ">937, c1=-393.484, c2=93.081 g=-108.740\n",
      ">938, c1=-390.224, c2=72.529 g=-110.202\n",
      ">939, c1=-385.249, c2=57.092 g=-157.353\n",
      ">940, c1=-403.840, c2=93.197 g=-140.434\n",
      ">941, c1=-398.621, c2=21.986 g=-183.441\n",
      ">942, c1=-400.090, c2=63.924 g=-168.089\n",
      ">943, c1=-398.253, c2=26.635 g=-177.232\n",
      ">944, c1=-390.445, c2=75.355 g=-166.780\n",
      ">945, c1=-395.598, c2=37.903 g=-209.331\n",
      ">946, c1=-398.607, c2=31.306 g=-234.657\n",
      ">947, c1=-398.568, c2=39.482 g=-245.134\n",
      ">948, c1=-408.603, c2=24.737 g=-272.748\n",
      ">949, c1=-407.317, c2=71.294 g=-272.893\n",
      ">950, c1=-393.911, c2=82.580 g=-263.403\n",
      ">951, c1=-396.564, c2=36.921 g=-290.099\n",
      ">952, c1=-396.925, c2=4.010 g=-304.157\n",
      ">953, c1=-402.109, c2=22.764 g=-320.960\n",
      ">954, c1=-406.115, c2=43.098 g=-330.354\n",
      ">955, c1=-388.553, c2=45.151 g=-335.706\n",
      ">956, c1=-410.428, c2=64.448 g=-333.219\n",
      ">957, c1=-391.267, c2=-82.021 g=-395.441\n",
      ">958, c1=-377.912, c2=-11.514 g=-388.724\n",
      ">959, c1=-408.305, c2=82.341 g=-379.677\n",
      ">960, c1=-396.291, c2=81.578 g=-365.148\n",
      ">961, c1=-413.851, c2=54.007 g=-402.340\n",
      ">962, c1=-399.093, c2=76.266 g=-384.387\n",
      ">963, c1=-401.288, c2=96.766 g=-387.711\n",
      ">964, c1=-354.140, c2=125.479 g=-365.963\n",
      ">965, c1=-389.347, c2=142.244 g=-358.720\n",
      ">966, c1=-386.454, c2=128.847 g=-362.505\n",
      ">967, c1=-388.726, c2=136.426 g=-352.607\n",
      ">968, c1=-374.160, c2=152.371 g=-324.728\n",
      ">969, c1=-395.812, c2=126.842 g=-359.121\n",
      ">970, c1=-352.090, c2=115.089 g=-353.015\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: generated_plot_0970.png and model_0970.h5\n"
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 50\n",
    "# create the critic\n",
    "critic = define_critic()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, critic)\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "print(dataset.shape)\n",
    "# train model\n",
    "train(generator, critic, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a44b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
